# Natural-Language-Processing-Course
ECS-189 Taught by [Zhou Yu](http://www.cs.cmu.edu/~zhouyu/) in UC Davis

## HW 1: Spell Correction
* Implement Noisy Channel
* Test 6 language models with training and dev data
* 6 Language Models: 
  1. Unigram Model
  2. Bigram Model 
  3. Smooth Unigram Model 
  4. Smooth Bigram Model
  5. Backoff Model: implemented with unsmoothed bigram and smoothed unigram
  6. Custom Model: implemented unsmooth trigram, unsmooth bigram, and smoothed unigram in backoff model
  
## HW 2: POS Tagging
* Implement Trigram Backoff HMM with deleted-interpolation
* Implement Trigram Viterbi Algorithm
* Train and test lanague model on English, Japanese, and Bulgarian
* Achieve 95% accuracy on English POS Tagging test data
* Achieve 94% accuracy on Japanese POS Tagging test data
* Achieve 89% accuracy on Bulgarian POS Tagging test data
